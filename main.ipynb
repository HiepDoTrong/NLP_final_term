{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/dotronghiep/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /home/dotronghiep/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/dotronghiep/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords, brown\n",
    "nltk.download('stopwords')\n",
    "nltk.download('brown')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>impossible to stop basically means russia is n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>indeed. may russia soil then selves in terror ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>goodnight family, thanks to everyone for your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>keep adding more sanctionsfastest way to get r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>russia does not get to rape ukraine in order t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>its already done de facto. east ukraineand cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>russia takes most of sievierodonetsk city in e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>biden says us to send ukraine 'advanced rocket...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>just in - biden us to send ukraine advanced ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>why do you suppose i do not understand that. i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1                                                  2\n",
       "0   1  0  impossible to stop basically means russia is n...\n",
       "1   2  0  indeed. may russia soil then selves in terror ...\n",
       "2   3  0  goodnight family, thanks to everyone for your ...\n",
       "3   4  0  keep adding more sanctionsfastest way to get r...\n",
       "4   5  0  russia does not get to rape ukraine in order t...\n",
       "5   6  1  its already done de facto. east ukraineand cri...\n",
       "6   7  1  russia takes most of sievierodonetsk city in e...\n",
       "7   8  0  biden says us to send ukraine 'advanced rocket...\n",
       "8   9  1  just in - biden us to send ukraine advanced ro...\n",
       "9  10  0  why do you suppose i do not understand that. i..."
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/dotronghiep/Documents/Datasets/Social_Listening/DataLabel.csv', header=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_row = df.iloc[:, 2].values\n",
    "y = df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_row, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4616\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4616\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lấy danh sách stopword\n",
    "stop = set(stopwords.words('english'))\n",
    "# stop = ()\n",
    "brown_words = set(word for word in brown.words() if word.lower() not in stop)|{\"biden\",\n",
    "                                                                               \"ukraine\",\"kiev\",\"kyiv\",\"zelensky\", \"ukrainian\", \"ukrainians\",\n",
    "                                                                               \"putin\",\"kremlin\", \"russia\", \"russian\", \"russians\",\n",
    "                                                                               \"not\", \"no\", \"nor\", \"against\", \"never\", \"nobody\", \"none\", \"nowhere\"}\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'[a-zA-Z]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma(text):\n",
    "    words = tokenizer.tokenize(text)\n",
    "    cleaned_words = [lemmatizer.lemmatize(word, pos='v') for word in words if word in brown_words]\n",
    "    return cleaned_words\n",
    "\n",
    "\n",
    "# Loại bỏ stop words từ mỗi văn bản trong danh sách X\n",
    "X_cleaned = [lemma(text) for text in X_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ukraine', 'every', 'right', 'attack', 'russia', 'point'],\n",
       " ['real', 'men', 'defend', 'country', 'people', 'respect'],\n",
       " ['well',\n",
       "  'honest',\n",
       "  'russian',\n",
       "  'visit',\n",
       "  'board',\n",
       "  'quite',\n",
       "  'time',\n",
       "  'russia',\n",
       "  'start',\n",
       "  'military',\n",
       "  'build',\n",
       "  'ukraine',\n",
       "  'border',\n",
       "  'last',\n",
       "  'year',\n",
       "  'call',\n",
       "  'journalist'],\n",
       " ['poor',\n",
       "  'russian',\n",
       "  'regime',\n",
       "  'world',\n",
       "  'say',\n",
       "  'no',\n",
       "  'brutal',\n",
       "  'invasion',\n",
       "  'play',\n",
       "  'victim',\n",
       "  'get',\n",
       "  'ukraine'],\n",
       " ['definitely', 'arm', 'ukraine', 'teeth', 'keep', 'russia'],\n",
       " ['legitimate',\n",
       "  'security',\n",
       "  'concern',\n",
       "  'already',\n",
       "  'countries',\n",
       "  'members',\n",
       "  'military',\n",
       "  'base',\n",
       "  'nuclear',\n",
       "  'capability',\n",
       "  'wipe',\n",
       "  'russia',\n",
       "  'map',\n",
       "  'ukraine',\n",
       "  'make',\n",
       "  'zero',\n",
       "  'difference',\n",
       "  'putin',\n",
       "  'know',\n",
       "  'join',\n",
       "  'could',\n",
       "  'not',\n",
       "  'invade',\n",
       "  'point'],\n",
       " ['ukraine',\n",
       "  'shut',\n",
       "  'listen',\n",
       "  'russia',\n",
       "  'like',\n",
       "  'shut',\n",
       "  'listen',\n",
       "  'us',\n",
       "  'argue',\n",
       "  'otherwise',\n",
       "  'accept',\n",
       "  'kind',\n",
       "  'absurd',\n",
       "  'prevalent',\n",
       "  'among',\n",
       "  'riddle',\n",
       "  'cat',\n",
       "  'ladies'],\n",
       " ['question',\n",
       "  'whole',\n",
       "  'population',\n",
       "  'suffer',\n",
       "  'action',\n",
       "  'russia',\n",
       "  'enable',\n",
       "  'formation',\n",
       "  'many',\n",
       "  'people',\n",
       "  'die',\n",
       "  'putin',\n",
       "  'meddle',\n",
       "  'ukraine',\n",
       "  'find',\n",
       "  'plenty',\n",
       "  'evidence',\n",
       "  'russian',\n",
       "  'military',\n",
       "  'know'],\n",
       " ['think',\n",
       "  'exactly',\n",
       "  'way',\n",
       "  'world',\n",
       "  'need',\n",
       "  'give',\n",
       "  'way',\n",
       "  'otherwise',\n",
       "  'nothing',\n",
       "  'loose',\n",
       "  'lot',\n",
       "  'damage',\n",
       "  'use',\n",
       "  'nuclear',\n",
       "  'power',\n",
       "  'hope',\n",
       "  'ukraine',\n",
       "  'military',\n",
       "  'ahead',\n",
       "  'way',\n",
       "  'deal',\n",
       "  'nuclear',\n",
       "  'threats'],\n",
       " ['russian', 'troop', 'ukraine', 'war', 'condemn']]"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cleaned[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gensim.downloader as api\n",
    "import csv\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max(len(sentence) for sentence in X_cleaned)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(X_cleaned, \n",
    "                 vector_size=100, \n",
    "                 window=11, \n",
    "                 min_count=5, \n",
    "                 workers=8, \n",
    "                 epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1754\n"
     ]
    }
   ],
   "source": [
    "vocabulary = model.wv.index_to_key\n",
    "print(f\"Vocabulary size: {len(vocabulary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monster: 0.4552\n",
      "madness: 0.4175\n",
      "century: 0.4027\n",
      "convince: 0.3900\n",
      "killers: 0.3874\n",
      "weak: 0.3870\n",
      "threats: 0.3753\n",
      "democracies: 0.3690\n",
      "heroes: 0.3632\n",
      "praise: 0.3568\n"
     ]
    }
   ],
   "source": [
    "# Tìm từ gần nhất \n",
    "similar_words = model.wv.most_similar(\"putin\")\n",
    "for word, score in similar_words:\n",
    "    print(f\"{word}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4613, 35, 100)\n",
      "(4613,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def vectorize(X, y, model=model):\n",
    "    X_vectors = []\n",
    "    y_vectors = []\n",
    "    # Chuyển từng từ trong mỗi câu thành vector biểu diễn và thêm padding\n",
    "    for sentence, label in zip(X, y):\n",
    "        # Tạo một danh sách để lưu trữ các vector biểu diễn của các từ trong câu\n",
    "        if sentence == []:\n",
    "            continue\n",
    "        sentence_vectors = []\n",
    "        for word in sentence:\n",
    "            # Kiểm tra xem từ đó có trong từ vựng của mô hình Word2Vec hay không\n",
    "            if word in model.wv:\n",
    "                word_vector = model.wv[word]\n",
    "                sentence_vectors.append(word_vector)\n",
    "            else:\n",
    "                # Nếu từ không có trong từ vựng, bạn có thể sử dụng một vector thay thế hoặc bỏ qua nó\n",
    "                # Ví dụ: word_vector = np.zeros((vector_size,))\n",
    "                pass\n",
    "\n",
    "        # Thêm padding cho câu để độ dài của mỗi câu là 35\n",
    "        while len(sentence_vectors) < 35:\n",
    "            sentence_vectors.append(np.zeros((100,)))  # Sử dụng vector zeros cho padding\n",
    "\n",
    "        # Chuyển danh sách các vector thành một tensor\n",
    "        sentence_tensor = torch.tensor(sentence_vectors)\n",
    "        # Thêm câu đã được padding vào danh sách X_vectors\n",
    "        X_vectors.append(sentence_tensor)\n",
    "        y_vectors.append(label)\n",
    "\n",
    "\n",
    "    # Chuyển danh sách X_vectors thành một tensor\n",
    "    X_padded = np.array(X_vectors)\n",
    "    y_padded = np.array(y_vectors)\n",
    "    return X_padded, y_padded\n",
    "\n",
    "# In ra kích thước của X_padded\n",
    "X_input, y_input = vectorize(X_cleaned, y_train)\n",
    "print(X_input.shape)\n",
    "print(y_input.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.6543352007865906\n",
      "Accuracy on validation set: 0.7118093174431203\n",
      "=========================================\n",
      "Epoch 10, Loss: 0.6069053411483765\n",
      "Accuracy on validation set: 0.7118093174431203\n",
      "=========================================\n",
      "Epoch 15, Loss: 0.6005474925041199\n",
      "Accuracy on validation set: 0.7118093174431203\n",
      "=========================================\n",
      "Epoch 20, Loss: 0.6029213070869446\n",
      "Accuracy on validation set: 0.7118093174431203\n",
      "=========================================\n",
      "Epoch 25, Loss: 0.5997281074523926\n",
      "Accuracy on validation set: 0.7118093174431203\n",
      "=========================================\n",
      "Epoch 30, Loss: 0.6005759835243225\n",
      "Accuracy on validation set: 0.7118093174431203\n",
      "=========================================\n",
      "Epoch 35, Loss: 0.5993765592575073\n",
      "Accuracy on validation set: 0.7118093174431203\n",
      "=========================================\n",
      "Epoch 40, Loss: 0.599163830280304\n",
      "Accuracy on validation set: 0.7118093174431203\n",
      "=========================================\n",
      "Epoch 45, Loss: 0.5978242754936218\n",
      "Accuracy on validation set: 0.7118093174431203\n",
      "=========================================\n",
      "Epoch 50, Loss: 0.5950351357460022\n",
      "Accuracy on validation set: 0.7118093174431203\n",
      "=========================================\n",
      "Epoch 55, Loss: 0.5832815170288086\n",
      "Accuracy on validation set: 0.7118093174431203\n",
      "=========================================\n",
      "Epoch 60, Loss: 0.5734872817993164\n",
      "Accuracy on validation set: 0.7085590465872156\n",
      "=========================================\n",
      "Epoch 65, Loss: 0.5658265948295593\n",
      "Accuracy on validation set: 0.7118093174431203\n",
      "=========================================\n",
      "Epoch 70, Loss: 0.55764240026474\n",
      "Accuracy on validation set: 0.6944745395449621\n",
      "=========================================\n",
      "Epoch 75, Loss: 0.5486646890640259\n",
      "Accuracy on validation set: 0.6998916576381365\n",
      "=========================================\n",
      "Epoch 80, Loss: 0.5372234582901001\n",
      "Accuracy on validation set: 0.6901408450704225\n",
      "=========================================\n",
      "Epoch 85, Loss: 0.5215244293212891\n",
      "Accuracy on validation set: 0.6923076923076923\n",
      "=========================================\n",
      "Epoch 90, Loss: 0.5053339004516602\n",
      "Accuracy on validation set: 0.6738894907908992\n",
      "=========================================\n",
      "Epoch 95, Loss: 0.4784221053123474\n",
      "Accuracy on validation set: 0.6966413867822319\n",
      "=========================================\n",
      "Epoch 100, Loss: 0.461497038602829\n",
      "Accuracy on validation set: 0.6879739978331527\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Khởi tạo hidden state và cell state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Đưa đầu vào qua LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Lấy output của lớp cuối cùng\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Định nghĩa các siêu tham số\n",
    "input_size = 100  # Kích thước của vectơ biểu diễn từ\n",
    "hidden_size = 128  # Kích thước của hidden state trong LSTM\n",
    "num_layers = 2  # Số lớp LSTM xếp chồng lên nhau\n",
    "num_classes = 2  # Số lớp đầu ra\n",
    "num_epochs = 100  # Số epoch\n",
    "lr=0.001\n",
    "\n",
    "# Khởi tạo mô hình\n",
    "lstm = LSTMClassifier(input_size, hidden_size, num_layers, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=lr)\n",
    "lstm.to(device)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_input, y_input, test_size=0.2, random_state=42, stratify=y_input)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_valid = torch.tensor(X_valid, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train).to(device)\n",
    "y_valid = torch.tensor(y_valid).to(device)\n",
    "# Huấn luyện mô hình\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Huấn luyện\n",
    "    lstm.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = lstm(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # In ra loss sau mỗi 5 epoch\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "        # Đánh giá mô hình trên tập validation\n",
    "        lstm.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = lstm(X_valid)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            accuracy = accuracy_score(y_valid.cpu(), predicted.cpu())\n",
    "            print(f\"Accuracy on validation set: {accuracy}\")\n",
    "            print(\"=========================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
